{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data for Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMP LINK TO REFER \n",
    "\n",
    "https://keras-team.github.io/keras-tuner/documentation/hyperparameters/\n",
    "\n",
    "https://keras-team.github.io/keras-tuner/documentation/tuners/\n",
    "\n",
    "https://keras.io/api/layers/initializers/#randomnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T08:24:29.610903Z",
     "start_time": "2020-04-30T08:24:29.598132Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\mypersonal_mentor\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\user\\anaconda2\\envs\\mypersonal_mentor\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\users\\user\\anaconda2\\envs\\mypersonal_mentor\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner  # you just need for installation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:06:46.623899Z",
     "start_time": "2020-05-02T21:06:46.612411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  ##### TF > 2.0\n",
    "import kerastuner as kt\n",
    "\n",
    "print(tf.__version__)\n",
    "print(kt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:02:28.374620Z",
     "start_time": "2020-05-02T21:02:28.369314Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # Normalization \n",
    "from tensorflow.keras import models, layers  # Sequnetial , Sub Class API \n",
    "from kerastuner import HyperModel, RandomSearch, Hyperband, BayesianOptimization\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.save_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  NN Model without HPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)  ## Doing fiting of scaleer on train\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)  # using scaler which was fitted on train on train\n",
    "x_test_scaled = scaler.transform(x_test)# using scaler which was fitted on train on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have regression problem where which i need to predict House Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.random.randn(200)\n",
    "#\n",
    "#bias = zeros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:05:24.510910Z",
     "start_time": "2020-05-02T21:05:24.438203Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()  # Sequentail approach of developing my TF Model \n",
    "\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=(x_train.shape[1],),\n",
    "                       kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(16, activation='relu', kernel_initializer='random_normal',\n",
    "                       bias_initializer='zeros'))\n",
    "\n",
    "\n",
    "model.add(layers.Dropout(0.1)) ## Adding Drop Out Layer \n",
    "\n",
    "\n",
    "model.add(layers.Dense(1))  # Output layer with Neuron = 1 \n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:05:25.887552Z",
     "start_time": "2020-05-02T21:05:24.849517Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 570.3118 - mse: 570.3118 - val_loss: 639.6743 - val_mse: 639.6743\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 566.9042 - mse: 566.9042 - val_loss: 635.9645 - val_mse: 635.9645\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 563.0008 - mse: 563.0008 - val_loss: 631.5813 - val_mse: 631.5813\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 558.3314 - mse: 558.3314 - val_loss: 625.6187 - val_mse: 625.6187\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 552.7308 - mse: 552.7308 - val_loss: 619.0966 - val_mse: 619.0966\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 545.7599 - mse: 545.7599 - val_loss: 611.0032 - val_mse: 611.0032\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 537.2849 - mse: 537.2849 - val_loss: 601.7495 - val_mse: 601.7495\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 528.2014 - mse: 528.2014 - val_loss: 590.6928 - val_mse: 590.6928\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 517.5443 - mse: 517.5443 - val_loss: 579.4479 - val_mse: 579.4479\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 505.9346 - mse: 505.9346 - val_loss: 567.4852 - val_mse: 567.4852\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 492.8487 - mse: 492.8487 - val_loss: 552.0883 - val_mse: 552.0883\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 477.9872 - mse: 477.9872 - val_loss: 537.8782 - val_mse: 537.8782\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 463.9436 - mse: 463.9436 - val_loss: 520.9137 - val_mse: 520.9137\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 448.7695 - mse: 448.7695 - val_loss: 505.1228 - val_mse: 505.1228\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 431.5538 - mse: 431.5538 - val_loss: 485.0654 - val_mse: 485.0654\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, validation_split=0.2, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:06:58.506753Z",
     "start_time": "2020-05-02T21:06:58.446239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 647us/step - loss: 458.2523 - mse: 458.2523\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(x_test_scaled, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:07:27.321927Z",
     "start_time": "2020-05-02T21:07:27.313823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE without tuning: 458.2522888183594\n"
     ]
    }
   ],
   "source": [
    "print('MSE without tuning: {}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:08:23.997581Z",
     "start_time": "2020-05-02T21:08:23.980702Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class RegressionHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = models.Sequential()\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=  hp.Int('units', 8, 64, 4, default=8),   # [8,12,16,20,24,28,32,36,40,44,48,52,56,62]\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                input_shape=input_shape,\n",
    "                kernel_initializer='random_normal', bias_initializer='zeros'   #hp.Choice is used to define a categorical hyperparameter such as the activation function. The search space below, named “dense_activation”, will choose between “relu”, “tanh”, and “sigmoid” functions, with a default value set to “relu”\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int('units', 16, 64, 4, default=16), #######  [ 16,20,24,28,32,36,40,44,48,52,56,60,64]\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'),\n",
    "                kernel_initializer='random_normal', bias_initializer='zeros'   # Both hp.Int and hp.Float requires a name, minimum value and maximum value, while the step size and default value is optional\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(\n",
    "            layers.Dropout(\n",
    "                hp.Float(\n",
    "                    'dropout',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.1,     # [0.0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1]\n",
    "                    default=0.005,\n",
    "                    step=0.01)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        model.add(layers.Dense(1, kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='rmsprop',loss='mse',metrics=['mse']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:08:25.153572Z",
     "start_time": "2020-05-02T21:08:25.148289Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (x_train.shape[1],)\n",
    "hypermodel = RegressionHyperModel(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import xgboost \n",
    "\n",
    "# xgb = xgboost(n_jobs = -1 )\n",
    "\n",
    "# GridSearchCV(xgb,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Random Search Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:08:26.210946Z",
     "start_time": "2020-05-02T21:08:25.978169Z"
    }
   },
   "outputs": [],
   "source": [
    "tuner_rs = RandomSearch(\n",
    "            hypermodel,\n",
    "            objective='mse',\n",
    "            seed=42,\n",
    "            max_trials=20,\n",
    "            executions_per_trial=2, overwrite=True,directory=os.path.normpath('C:\\\\Arihant\\\\Personal\\\\Mentorship\\\\UpGrad\\\\KerasTuner_Random')\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#max_trials represents the number of hyperparameter combinations that will be tested by the tuner, while execution_per_trial is the number of models that should be built and fit for each trial for robustness purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:08:51.610609Z",
     "start_time": "2020-05-02T21:08:28.593385Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_rs.search(x_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=0)  \n",
    "\n",
    "## Main code which whill trigger your HPT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:09:03.713162Z",
     "start_time": "2020-05-02T21:09:03.369393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 892us/step - loss: 94.0469 - mse: 94.0469\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner_rs.get_best_models(num_models=1)[0]\n",
    "mse_rs = best_model.evaluate(x_test_scaled, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 273\n",
      "Trainable params: 273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 60)                840       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 4,561\n",
      "Trainable params: 4,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:09:42.166321Z",
     "start_time": "2020-05-02T21:09:42.154977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random search MSE:  94.0468978881836\n"
     ]
    }
   ],
   "source": [
    "print('Random search MSE: ', mse_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build, Run and Evaluate Hyperband Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:10:39.154589Z",
     "start_time": "2020-05-02T21:10:38.588470Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project C:\\Arihant\\Personal\\Mentorship\\UpGrad\\KerasTuner_Hyperband\\untitled_project\\oracle.json\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Reloading Tuner from C:\\Arihant\\Personal\\Mentorship\\UpGrad\\KerasTuner_Hyperband\\untitled_project\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "4/4 [==============================] - 0s 707us/step - loss: 589.9302 - mse: 589.9302\n"
     ]
    }
   ],
   "source": [
    "tuner_hb = Hyperband(\n",
    "            hypermodel,\n",
    "            max_epochs=5,\n",
    "            objective='mse',\n",
    "            seed=42,\n",
    "            executions_per_trial=2 ,directory=os.path.normpath('C:\\\\Arihant\\\\Personal\\\\Mentorship\\\\UpGrad\\\\KerasTuner_Hyperband')\n",
    "       )\n",
    "\n",
    "tuner_hb.search(x_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
    "\n",
    "best_model = tuner_hb.get_best_models(num_models=1)[0]\n",
    "mse_hb = best_model.evaluate(x_test_scaled, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:10:59.684682Z",
     "start_time": "2020-05-02T21:10:59.673302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperband MSE:  589.93017578125\n"
     ]
    }
   ],
   "source": [
    "print('Hyperband MSE: ', mse_hb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build, Run and Evaluate Bayesian Optimization Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:11:38.827543Z",
     "start_time": "2020-05-02T21:11:38.179694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project C:\\Arihant\\Personal\\Mentorship\\UpGrad\\KerasTuner_Bayesian\\untitled_project\\oracle.json\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Reloading Tuner from C:\\Arihant\\Personal\\Mentorship\\UpGrad\\KerasTuner_Bayesian\\untitled_project\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "4/4 [==============================] - 0s 771us/step - loss: 458.7108 - mse: 458.7108\n"
     ]
    }
   ],
   "source": [
    "tuner_bo = BayesianOptimization(\n",
    "            hypermodel,\n",
    "            objective='mse',\n",
    "            max_trials=10,\n",
    "            seed=42,\n",
    "            executions_per_trial=2,\n",
    "            directory=os.path.normpath('C:\\\\Arihant\\\\Personal\\\\Mentorship\\\\UpGrad\\\\KerasTuner_Bayesian')\n",
    "        \n",
    "        )\n",
    "\n",
    "tuner_bo.search(x_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
    "\n",
    "best_model = tuner_bo.get_best_models(num_models=1)[0]\n",
    "mse_bo = best_model.evaluate(x_test_scaled, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:11:52.416840Z",
     "start_time": "2020-05-02T21:11:52.406188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Optimization MSE:  458.7108154296875\n"
     ]
    }
   ],
   "source": [
    "print('Bayesian Optimization MSE: ', mse_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
